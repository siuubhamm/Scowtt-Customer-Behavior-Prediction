{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425cdbdc",
   "metadata": {},
   "source": [
    "## Training models for Customer Product Purchase Propensity and Purchase Order Value prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12243a2e",
   "metadata": {},
   "source": [
    "### Customer Purchase Propensity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccdc3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import average_precision_score, mean_absolute_error, r2_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from category_encoders import TargetEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14442c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"tot_pymt_sqntl\",\n",
    "    \"avg_pymt_instllmnt\",\n",
    "    \"tot_pymt_val\",\n",
    "    \"tot_pymt_boleto\",\n",
    "    \"tot_pymt_debit_card\",\n",
    "    \"tot_pymt_not_defined\",\n",
    "    \"tot_pymt_voucher\",\n",
    "    \"avg_rev_score\",\n",
    "    \"avg_rev_title_length\",\n",
    "    \"avg_rev_length\",\n",
    "    \"days_since_lst_rev_creation\",\n",
    "    \"num_products\",\n",
    "    \"avg_order_size\",\n",
    "    \"tot_order_freight_value\",\n",
    "    \"num_orders_approved\",\n",
    "    \"num_orders_canceled\",\n",
    "    \"num_orders_created\",\n",
    "    \"num_orders_invoiced\",\n",
    "    \"num_orders_processing\",\n",
    "    \"num_orders_shipped\",\n",
    "    \"num_orders_unavailable\",\n",
    "    \"tot_pymt_val_canceled\",\n",
    "    \"tot_pymt_val_invoiced\",\n",
    "    \"tot_pymt_val_processing\",\n",
    "    \"tot_pymt_val_shipped\",\n",
    "    \"tot_pymt_val_unavailable\",\n",
    "    \"num_rev_delivered\",\n",
    "    \"num_products_created\",\n",
    "    \"num_products_unavailable\",\n",
    "    \"avg_order_size_created\",\n",
    "    \"avg_order_size_unavailable\",\n",
    "    \"tot_order_price_created\",\n",
    "    \"tot_order_price_unavailable\",\n",
    "    \"tot_order_freight_value_canceled\",\n",
    "    \"tot_order_freight_value_created\",\n",
    "    \"tot_order_value_created\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8687f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNAPSHOT_MONTH = \"06-2018\"\n",
    "SNAPSHOT_PATH = f\"../../Data/processed/customer_snapshots/{SNAPSHOT_MONTH}/customer_unique_snapshot.csv\"\n",
    "ORDERS_PATH = \"../../Data/raw/olist_orders_dataset.csv\"\n",
    "INTERMEDIATE_ORDERS_PATH = \"../../Data/processed/intermediate_output_orders.csv\"\n",
    "CUSTOMERS_PATH = \"../../Data/raw/olist_customers_dataset.csv\"\n",
    "\n",
    "CUTOFF_DATE = pd.Timestamp(\"2018-06-30\")\n",
    "HORIZON_DAYS = 90\n",
    "HORIZON_END = CUTOFF_DATE + pd.Timedelta(days=HORIZON_DAYS)\n",
    "RECENCY_THRESHOLD = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6674179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = pd.read_csv(SNAPSHOT_PATH).set_index(\"customer_unique_id\")\n",
    "\n",
    "X_filtered = X_raw[\n",
    "    X_raw[\"days_since_lst_order_purchased\"] <= RECENCY_THRESHOLD\n",
    "].copy()\n",
    "\n",
    "orders = pd.read_csv(\n",
    "    ORDERS_PATH,\n",
    "    parse_dates=[\"order_purchase_timestamp\"]\n",
    ")\n",
    "\n",
    "order_values = pd.read_csv(\n",
    "    INTERMEDIATE_ORDERS_PATH\n",
    ")[[\"order_id\", \"tot_order_value\"]]\n",
    "\n",
    "customers = pd.read_csv(\n",
    "    CUSTOMERS_PATH\n",
    ")[[\"customer_id\", \"customer_unique_id\"]]\n",
    "\n",
    "orders = orders.merge(order_values, on=\"order_id\", how=\"inner\")\n",
    "\n",
    "future_orders = orders[\n",
    "    (orders[\"order_purchase_timestamp\"] > CUTOFF_DATE) &\n",
    "    (orders[\"order_purchase_timestamp\"] <= HORIZON_END)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591447a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = future_orders.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "labels = labels.groupby(\"customer_unique_id\").agg(\n",
    "    y_propensity=(\"order_id\", lambda x: 1),\n",
    "    y_value=(\"tot_order_value\", \"sum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5238cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_filtered.join(labels, how=\"left\")\n",
    "\n",
    "data[\"y_propensity\"] = data[\"y_propensity\"].fillna(0).astype(int)\n",
    "data[\"y_value\"] = data[\"y_value\"].fillna(0.0)\n",
    "\n",
    "final_feature_list = [\n",
    "    f for f in FEATURES if f in data.columns\n",
    "]\n",
    "\n",
    "X_model = data[final_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb6f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, yv_train, yv_val = train_test_split(\n",
    "    X_model,\n",
    "    data[\"y_propensity\"],\n",
    "    data[\"y_value\"],\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=data[\"y_propensity\"]   \n",
    ")\n",
    "\n",
    "X_train = X_train.fillna(0)\n",
    "X_val = X_val.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03007ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_tune(model_class, param_grid, X_train, y_train, X_val, y_val, fixed_params=None):\n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    fixed_params = fixed_params or {}\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        model = model_class(**fixed_params, **params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        score = average_precision_score(y_val, preds)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "    return best_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b21ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Best Params: {'C': 1.0, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Val PR-AUC: 0.0128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1.0],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "lr_fixed = {\n",
    "    \"solver\": \"liblinear\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "lr_model, lr_params, lr_score = train_and_tune(\n",
    "    LogisticRegression,\n",
    "    lr_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    fixed_params=lr_fixed\n",
    ")\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Best Params:\", lr_params)\n",
    "print(f\"Val PR-AUC: {lr_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a957eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "Best Params: {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "Val PR-AUC: 0.0182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [None, 3, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5]\n",
    "}\n",
    "\n",
    "rf_fixed = {\n",
    "    \"n_jobs\": -1,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "rf_model, rf_params, rf_score = train_and_tune(\n",
    "    RandomForestClassifier,\n",
    "    rf_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    fixed_params=rf_fixed\n",
    ")\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "print(\"Best Params:\", rf_params)\n",
    "print(f\"Val PR-AUC: {rf_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b08e283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Best Params: {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Val PR-AUC: 0.0684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
    "\n",
    "xgb_fixed = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"aucpr\",\n",
    "    \"scale_pos_weight\": pos_weight,\n",
    "    \"use_label_encoder\": False,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "xgb_model, xgb_params, xgb_score = train_and_tune(\n",
    "    XGBClassifier,\n",
    "    xgb_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    fixed_params=xgb_fixed\n",
    ")\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "print(\"Best Params:\", xgb_params)\n",
    "print(f\"Val PR-AUC: {xgb_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b13233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepurchaseMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_on_quarter(\n",
    "    snapshot_month,\n",
    "    model=None,\n",
    "    scaler=None,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    val_frac=0.2\n",
    "):\n",
    "    SNAPSHOT_PATH = f\"../../Data/processed/customer_snapshots/{snapshot_month}/customer_unique_snapshot.csv\"\n",
    "\n",
    "    df = pd.read_csv(SNAPSHOT_PATH).set_index(\"customer_unique_id\")\n",
    "    df = df[df[\"days_since_lst_order_purchased\"] <= RECENCY_THRESHOLD].copy()\n",
    "\n",
    "    df = df.join(labels, how=\"left\")\n",
    "    df[\"y_propensity\"] = df[\"y_propensity\"].fillna(0).astype(int)\n",
    "\n",
    "    final_features = [f for f in FEATURES if f in df.columns]\n",
    "\n",
    "    X_raw = df[final_features].fillna(0).values\n",
    "    y_raw = df[\"y_propensity\"].values\n",
    "\n",
    "    X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "        X_raw,\n",
    "        y_raw,\n",
    "        test_size=val_frac,\n",
    "        random_state=42,\n",
    "        stratify=y_raw\n",
    "    )\n",
    "\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_raw)\n",
    "    else:\n",
    "        X_train = scaler.transform(X_train_raw)\n",
    "\n",
    "    X_val = scaler.transform(X_val_raw)\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_train),\n",
    "        torch.FloatTensor(y_train).view(-1, 1)\n",
    "    )\n",
    "\n",
    "    class_counts = np.bincount(y_train.astype(int))\n",
    "    class_weights = 1.0 / class_counts\n",
    "    sample_weights = class_weights[y_train.astype(int)]\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    if model is None:\n",
    "        model = RepurchaseMLP(X_train.shape[1])\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    print(f\"\\n--- Training | Snapshot {snapshot_month} ---\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_probs = model(torch.FloatTensor(X_train)).numpy().ravel()\n",
    "                val_probs = model(torch.FloatTensor(X_val)).numpy().ravel()\n",
    "\n",
    "                train_pr = average_precision_score(y_train, train_probs)\n",
    "                val_pr = average_precision_score(y_val, val_probs)\n",
    "\n",
    "                train_roc = roc_auc_score(y_train, train_probs)\n",
    "                val_roc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "                print(\n",
    "                    f\"Epoch {epoch:03d} | \"\n",
    "                    f\"Loss: {epoch_loss/len(train_loader):.4f} | \"\n",
    "                    f\"Train PR: {train_pr:.4f} | Val PR: {val_pr:.4f} | \"\n",
    "                    f\"Train ROC: {train_roc:.4f} | Val ROC: {val_roc:.4f}\"\n",
    "                )\n",
    "\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d56d4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training | Snapshot 06-2018 ---\n",
      "Epoch 001 | Loss: 0.6600 | Train PR: 0.0324 | Val PR: 0.0140 | Train ROC: 0.7207 | Val ROC: 0.6597\n",
      "Epoch 010 | Loss: 0.4419 | Train PR: 0.1264 | Val PR: 0.0071 | Train ROC: 0.9178 | Val ROC: 0.5256\n",
      "Epoch 020 | Loss: 0.3525 | Train PR: 0.2988 | Val PR: 0.0103 | Train ROC: 0.9637 | Val ROC: 0.5264\n",
      "Epoch 030 | Loss: 0.3041 | Train PR: 0.3428 | Val PR: 0.0133 | Train ROC: 0.9773 | Val ROC: 0.5370\n",
      "Epoch 040 | Loss: 0.2823 | Train PR: 0.4254 | Val PR: 0.0104 | Train ROC: 0.9805 | Val ROC: 0.5385\n",
      "Epoch 050 | Loss: 0.2635 | Train PR: 0.4423 | Val PR: 0.0088 | Train ROC: 0.9836 | Val ROC: 0.5291\n",
      "Epoch 060 | Loss: 0.2501 | Train PR: 0.4700 | Val PR: 0.0082 | Train ROC: 0.9859 | Val ROC: 0.5378\n",
      "Epoch 070 | Loss: 0.2420 | Train PR: 0.4525 | Val PR: 0.0100 | Train ROC: 0.9878 | Val ROC: 0.5246\n",
      "Epoch 080 | Loss: 0.2419 | Train PR: 0.5402 | Val PR: 0.0075 | Train ROC: 0.9886 | Val ROC: 0.5241\n",
      "Epoch 090 | Loss: 0.2418 | Train PR: 0.5367 | Val PR: 0.0083 | Train ROC: 0.9892 | Val ROC: 0.5241\n",
      "Epoch 100 | Loss: 0.2287 | Train PR: 0.5516 | Val PR: 0.0081 | Train ROC: 0.9905 | Val ROC: 0.5241\n"
     ]
    }
   ],
   "source": [
    "quarters = [\"06-2018\"]\n",
    "\n",
    "current_model = None\n",
    "current_scaler = None\n",
    "\n",
    "for q in quarters:\n",
    "    current_model, current_scaler = train_on_quarter(\n",
    "        q,\n",
    "        model=current_model,\n",
    "        scaler=current_scaler,\n",
    "        epochs=100\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        current_model.state_dict(),\n",
    "        f\"repurchase_mlp_progressive_{q}.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d193f38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Models/Purchase Propensity/xgb_model_model_06_2018.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb_model, \"../../Models/Purchase Propensity/xgb_model_model_06_2018.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206ae73",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- Class Imbalance: the number of people who go for repeat purchases are very low(~3%), indicating that there is an imbalance in the target variable.\n",
    "\n",
    "- Logistic Regression performs poorly indicating a linear is not enough.\n",
    "- Random Forest gives slight improvement over LR.\n",
    "- XGBoost gives the best results on the validation set.\n",
    "- MLP overfits the training data and does not generalize well on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a379f92",
   "metadata": {},
   "source": [
    "### Predicting Customer Purchase Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5de6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Data/processed/customer_snapshots/10-2018/customer_unique_snapshot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a6a0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF_DAYS = 90\n",
    "TARGET = \"avg_order_value\"\n",
    "\n",
    "df_value = df[df[\"num_orders\"] > 1].copy()\n",
    "df_value = df_value.dropna(subset = [TARGET])\n",
    "\n",
    "cat_features = [\n",
    "    \"customer_city\",\n",
    "    \"customer_state\",\n",
    "    \"pref_prod_category\",\n",
    "    \"pref_prod_category_english\",\n",
    "]\n",
    "\n",
    "for col in cat_features:\n",
    "    df_value[col] = df_value[col].astype(\"category\")\n",
    "\n",
    "df_value[\"y\"] = np.log1p(df_value[TARGET])\n",
    "\n",
    "train_mask = df_value[\"days_since_lst_order_purchased\"] > CUTOFF_DAYS\n",
    "val_mask   = df_value[\"days_since_lst_order_purchased\"] <= CUTOFF_DAYS\n",
    "\n",
    "X_train = df_value.loc[train_mask, FEATURES]\n",
    "y_train = df_value.loc[train_mask, \"y\"]\n",
    "\n",
    "X_val = df_value.loc[val_mask, FEATURES]\n",
    "y_val = df_value.loc[val_mask, \"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5c02bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in FEATURES:\n",
    "    if X_train[col].isna().all():\n",
    "        X_train[col] = 0.0\n",
    "        X_val[col]   = 0.0\n",
    "    else:\n",
    "        med = X_train[col].median()\n",
    "        X_train[col] = X_train[col].fillna(med)\n",
    "        X_val[col]   = X_val[col].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "809249d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not X_train.isna().any().any()\n",
    "assert not X_val.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d98383fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_tune_regressor(\n",
    "    model_class,\n",
    "    param_grid,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    fixed_params=None\n",
    "):\n",
    "    best_mae = np.inf\n",
    "    best_rmse = np.inf\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    fixed_params = fixed_params or {}\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        model = model_class(**fixed_params, **params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "\n",
    "        mae = mean_absolute_error(np.expm1(y_val), np.expm1(preds))\n",
    "        rmse = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(preds)))\n",
    "\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_rmse = rmse\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "    return best_model, best_params, best_mae, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81edc55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge Regression ===\n",
      "Best Params: {'alpha': 10.0}\n",
      "MAE: 40282.199 | RMSE: 598085.319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge_grid = {\n",
    "    \"alpha\": [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "ridge_model, ridge_params, ridge_mae, ridge_rmse = train_and_tune_regressor(\n",
    "    Ridge,\n",
    "    ridge_grid,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val\n",
    ")\n",
    "\n",
    "print(\"=== Ridge Regression ===\")\n",
    "print(\"Best Params:\", ridge_params)\n",
    "print(f\"MAE: {ridge_mae:.3f} | RMSE: {ridge_rmse:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f72799e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Regressor ===\n",
      "Best Params: {'max_depth': None, 'max_features': 0.7, 'min_samples_leaf': 5, 'n_estimators': 300}\n",
      "MAE: 17.169 | RMSE: 143.738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_grid = {\n",
    "    \"n_estimators\": [300, 600],\n",
    "    \"max_depth\": [None, 8, 12],\n",
    "    \"min_samples_leaf\": [5, 10],\n",
    "    \"max_features\": [\"sqrt\", 0.7]\n",
    "}\n",
    "\n",
    "rf_fixed = {\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "rf_model, rf_params, rf_mae, rf_rmse = train_and_tune_regressor(\n",
    "    RandomForestRegressor,\n",
    "    rf_grid,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    fixed_params=rf_fixed\n",
    ")\n",
    "\n",
    "print(\"=== Random Forest Regressor ===\")\n",
    "print(\"Best Params:\", rf_params)\n",
    "print(f\"MAE: {rf_mae:.3f} | RMSE: {rf_rmse:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "106367f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Regressor ===\n",
      "Best Params: {'colsample_bytree': 0.8, 'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 800, 'subsample': 0.8}\n",
      "MAE: 23.207 | RMSE: 173.661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_grid = {\n",
    "    \"max_depth\": [5, 8],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"n_estimators\": [400, 800],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.8]\n",
    "}\n",
    "\n",
    "xgb_fixed = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"min_child_weight\": 50,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "xgb_model, xgb_params, xgb_mae, xgb_rmse = train_and_tune_regressor(\n",
    "    XGBRegressor,\n",
    "    xgb_grid,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    fixed_params=xgb_fixed\n",
    ")\n",
    "\n",
    "print(\"=== XGBoost Regressor ===\")\n",
    "print(\"Best Params:\", xgb_params)\n",
    "print(f\"MAE: {xgb_mae:.3f} | RMSE: {xgb_rmse:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88a41af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              true        pred\n",
      "decile                        \n",
      "0        38.386739   37.661090\n",
      "1        60.163333   58.832831\n",
      "2        73.706970   72.727099\n",
      "3        87.740217   89.592325\n",
      "4       107.666232  105.728295\n",
      "5       117.980000  117.404114\n",
      "6       136.867993  140.649913\n",
      "7       166.291187  167.512722\n",
      "8       210.915000  211.398388\n",
      "9       570.191630  449.107831\n"
     ]
    }
   ],
   "source": [
    "log_preds = rf_model.predict(X_val)\n",
    "preds = np.expm1(log_preds)\n",
    "true_vals = np.expm1(y_val)\n",
    "\n",
    "eval_df = pd.DataFrame({\n",
    "    \"true\": true_vals,\n",
    "    \"pred\": preds\n",
    "})\n",
    "\n",
    "eval_df[\"decile\"] = pd.qcut(\n",
    "    eval_df[\"pred\"],\n",
    "    q=10,\n",
    "    labels=False,\n",
    "    duplicates=\"drop\"\n",
    ")\n",
    "\n",
    "decile_summary = eval_df.groupby(\"decile\")[[\"true\", \"pred\"]].mean()\n",
    "\n",
    "print(decile_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea5cc9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Models/Order Value/rf_value_model_06_2018.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf_model, \"../../Models/Order Value/rf_value_model_06_2018.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba2d3f",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- Linear Regression performs very poorly, showing that a linear model in itself is not enough to capture the customer behavior.\n",
    "- Random Forest and XGBoost Regressor fit the training data in a much better way.\n",
    "- The best results are from Random Forest Regressor\n",
    "- Decile level scores suggest that the model is able to closely predict the order values for top o9 deciles. There is some deviation in the 10th decile."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
